{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PARSE XML FILES\n",
    "2. TURN INTO TREE\n",
    "3. IF FAILS, PARSE AS MANY OF THE ENTRIES AS POSSIBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 XML files found, 285 unique. duplicates = []\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "os.chdir(repo.working_tree_dir)\n",
    "\n",
    "# srcpaths=(\n",
    "#     \"traces-1m-worker_3_overnight_portclash\",\n",
    "#     \"traces-1m-worker_4_overnight_fixportclash\",\n",
    "# )\n",
    "srcpaths=(\n",
    "    \"trace_run_3_success_3h/traces-10m/logs-xmls\",\n",
    ")\n",
    "\n",
    "xmls = []\n",
    "for d in srcpaths:\n",
    "    l = list(Path(d).glob(\"*.xml\"))\n",
    "    xmls += l\n",
    "print(len(xmls), \"XML files found,\", len(set([f.name for f in xmls])), \"unique. duplicates =\", [f for f in xmls if [g.name for g in xmls].count(f.name) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstdir=Path(\"postprocessed\")\n",
    "\n",
    "if dstdir.exists():\n",
    "    shutil.rmtree(dstdir)\n",
    "dstdir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 285/285 [56:50<00:00, 11.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND 1: 150 files failed parsing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12980"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "\n",
    "successes_1 = []\n",
    "failed_1 = []\n",
    "for fpath in tqdm.tqdm(xmls):\n",
    "    try:\n",
    "        root = ET.parse(fpath).getroot()\n",
    "        # print(fpath, \"parsed successfully\")\n",
    "        successes_1.append(fpath)\n",
    "        shutil.copyfile(fpath, dstdir/fpath.name)\n",
    "    except ET.ParseError as ex:\n",
    "        # print(\"exception\", type(ex).__name__, ex, \"parsing\", fpath)\n",
    "        failed_1.append(fpath)\n",
    "\n",
    "print(\"ROUND 1:\", len(failed_1), \"files failed parsing\")\n",
    "(dstdir/\"1_repair_success_1.txt\").write_text(\"\\n\".join(map(str, successes_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "\n",
    "fuzzer_start = re.compile(r'''<call[^>]*method=\"[^.\"]+.fuzzerTestOneInput\\([^)]+\\)\"[^>]*''')\n",
    "fuzzer_almost_end = re.compile(r'''<tracepoint[^>]+>''')\n",
    "method_re = re.compile(r'''method=\"[^.\"]+.fuzzerTestOneInput\\([^)]+\\)\"''')\n",
    "exit_re = re.compile(r'''type=\"exit\"''')\n",
    "fuzzer_real_end = re.compile(r'''</call>''')\n",
    "\n",
    "\n",
    "from xml.dom import minidom\n",
    "from xml.parsers.expat import ExpatError\n",
    "\n",
    "def prettify(rough_string):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    # rough_string = ET.tostring(elem)\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    \n",
    "    # text = reparsed.toprettyxml(indent=\" \" * 2)\n",
    "    # return \"\".join(text.splitlines(keepends=True)[1:])\n",
    "    \n",
    "    # return reparsed.childNodes[0].toprettyxml(indent=\" \" * 2)\n",
    "    \n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "def recover_functions(fpath):\n",
    "    with open(fpath) as f:\n",
    "        xmlstring = f.read()\n",
    "    xmllines = xmlstring.splitlines(keepends=True)\n",
    "    it = iter(xmllines)\n",
    "    repair_path = Path(str(fpath) + \".repair.xml\")\n",
    "    failed_functions = 0\n",
    "    all_functions = 0\n",
    "    with open(repair_path, \"w\") as outf:\n",
    "        with tqdm.tqdm(it, total=len(xmllines), desc=\"deconstruct into fuzzer target calls\") as pbar:\n",
    "            it = iter(pbar)\n",
    "            fuzz_functions = []\n",
    "            current_fuzz_function = None\n",
    "            try:\n",
    "                outf.write(next(it))\n",
    "                while True:\n",
    "                    line = next(it)\n",
    "                    if fuzzer_start.search(line):\n",
    "                        # print(\"start at\", line)\n",
    "                        # start fuzzed function\n",
    "                        current_fuzz_function = []\n",
    "                    if current_fuzz_function is not None:\n",
    "                        current_fuzz_function.append(line)\n",
    "                    m = fuzzer_almost_end.search(line)\n",
    "                    if m:\n",
    "                        tag = m.group(0)\n",
    "                        if method_re.search(tag) and exit_re.search(tag):\n",
    "                            # print(\"end at\", line)\n",
    "                            while True:\n",
    "                                line = next(it)\n",
    "                                # print(\"search end\", line)\n",
    "                                current_fuzz_function.append(line)\n",
    "                                if fuzzer_real_end.search(line):\n",
    "                                    # cap off fuzzed function\n",
    "                                    # print(\"end\", line)\n",
    "                                    all_functions += 1\n",
    "                                    try:\n",
    "                                        func_xml = \"\".join(current_fuzz_function)\n",
    "                                        # ET.fromstring(func_xml)\n",
    "                                        # print(func_xml)\n",
    "                                        func_xml = \"\".join(prettify(func_xml).splitlines(keepends=True)[1:])\n",
    "                                        outf.write(func_xml + \"\\n\")\n",
    "                                    except (ExpatError, ET.ParseError):\n",
    "                                        failed_functions += 1\n",
    "                                    pbar.set_postfix({\"all\": all_functions, \"failed\": failed_functions})\n",
    "                                    break\n",
    "            except StopIteration:\n",
    "                pass\n",
    "        outf.write(\"</trace>\")\n",
    "    \n",
    "#     print(\"found\", len(fuzz_functions), \"functions\")\n",
    "\n",
    "#     success_functions = []\n",
    "#     failed_functions = 0\n",
    "#     pbar = tqdm.tqdm(fuzz_functions, desc=\"parse individual fuzzer targets\")\n",
    "#     for fuzzed_function in pbar:\n",
    "#         try:\n",
    "#             root = ET.ElementTree(ET.fromstring(fuzzed_function)).getroot()\n",
    "#             # ET.indent(root, space=\"\\t\", level=0)\n",
    "#             success_functions.append(ET.tostring(root, encoding='unicode', method='xml'))\n",
    "#         except ET.ParseError as ex:\n",
    "#             # print(\"function exception\", type(ex), ex, \"parsing\", fpath)\n",
    "#             # print(fuzzed_function)\n",
    "#             failed_functions += 1\n",
    "#         pbar.set_postfix({\"failed\": failed_functions})\n",
    "    # print(\"failed\", failed_functions, \"out of\", all_functions, \"functions\")\n",
    "\n",
    "#     success_text = \"\\n\".join((xmllines[0], \"\".join(success_functions), \"</trace>\"))\n",
    "#     success_text = prettify(success_text)\n",
    "#     repair_path.write_text(\"\".join(success_text))\n",
    "    return repair_path\n",
    "\n",
    "# repair_path = recover_functions(\"traces-1m-worker_3_overnight_portclash/trace-apache-commons-cli-ParserFuzzer.xml\")\n",
    "# root = ET.parse(repair_path).getroot()\n",
    "# repair_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 3756964/3756964 [04:36<00:00, 1356\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 307/307 [00:00<00:00, 400015.95it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 2384900/2384900 [02:28<00:00, 1601\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 173/173 [00:00<00:00, 595253.97it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 37012/37012 [00:00<00:00, 1162660.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 35773/35773 [00:00<00:00, 1161475.\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 39325/39325 [00:00<00:00, 1196855.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 36378/36378 [00:00<00:00, 1132280.\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 15984/15984 [00:00<00:00, 1260278.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 40046572/40046572 [1:09:49<00:00, \u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1902/1902 [00:00<00:00, 1047749.70\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5009/5009 [00:00<00:00, 1040784.14\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 1661/1661 [00:00<00:00, 61981.66it\n",
      "deconstruct into fuzzer target calls: 100%|█| 81004/81004 [00:01<00:00, 40850.01\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 250352/250352 [00:04<00:00, 57237.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 40/40 [00:00<00:00, 356204.16it/s]\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 2285/2285 [00:00<00:00, 1127527.60\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 33320/33320 [00:00<00:00, 674196.5\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 3853327/3853327 [04:09<00:00, 1545\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9292/9292 [00:00<00:00, 1269701.02\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 32211/32211 [00:00<00:00, 34796.05\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1371/1371 [00:00<00:00, 1034987.54\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 20765/20765 [00:00<00:00, 1051690.\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 4133899/4133899 [05:20<00:00, 1288\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 368/368 [00:00<00:00, 873022.55it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 2841845/2841845 [02:55<00:00, 1623\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 138723/138723 [00:00<00:00, 126174\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5009/5009 [00:00<00:00, 1353690.00\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 3744975/3744975 [04:43<00:00, 1323\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 40372/40372 [00:00<00:00, 779572.2\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 3926/3926 [00:00<00:00, 875243.83i\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 18340/18340 [00:00<00:00, 30128.05\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 34824/34824 [00:10<00:00, 3280.62i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 20491/20491 [00:00<00:00, 966711.4\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 9675/9675 [00:00<00:00, 871317.96i\n",
      "deconstruct into fuzzer target calls: 100%|█| 656/656 [00:00<00:00, 479766.94it/\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 205/205 [00:00<00:00, 740596.31it/\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 3915727/3915727 [04:59<00:00, 1307\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1009/1009 [00:00<00:00, 105928.43i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 4705799/4705799 [05:45<00:00, 1361\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1103655/1103655 [00:00<00:00, 1208\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35961/35961 [00:00<00:00, 1112022.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 35555/35555 [00:00<00:00, 1074528.\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1627721/1627721 [00:01<00:00, 1315\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 534305/534305 [00:00<00:00, 138565\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 6106567/6106567 [09:10<00:00, 1108\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1039/1039 [00:00<00:00, 754350.33i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 547/547 [00:00<00:00, 937207.63it/\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 205/205 [00:00<00:00, 592579.13it/\n",
      "deconstruct into fuzzer target calls: 100%|█| 1132257/1132257 [00:01<00:00, 8965\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5511216/5511216 [07:30<00:00, 1222\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 83662/83662 [00:00<00:00, 1154197.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 3786/3786 [00:00<00:00, 1106594.77\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 1751967/1751967 [01:47<00:00, 1628\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9660/9660 [00:00<00:00, 407074.88i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 445346/445346 [00:00<00:00, 122527\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35559/35559 [00:00<00:00, 1010811.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 13540/13540 [00:00<00:00, 722686.5\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 35030/35030 [00:00<00:00, 914597.7\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 6383205/6383205 [09:59<00:00, 1064\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5305801/5305801 [04:58<00:00, 1775\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 881221/881221 [00:55<00:00, 15890.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 374644/374644 [00:22<00:00, 16809.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9675/9675 [00:00<00:00, 1007820.47\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 107140/107140 [00:00<00:00, 131463\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 8423941/8423941 [13:42<00:00, 1023\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 801150/801150 [01:00<00:00, 13308.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 228/228 [00:00<00:00, 219486.19it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 947169/947169 [00:44<00:00, 21161.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 550250/550250 [00:00<00:00, 136109\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 42384/42384 [00:01<00:00, 22022.60\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 141745/141745 [00:00<00:00, 123713\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 2373643/2373643 [02:31<00:00, 1569\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 516572/516572 [00:00<00:00, 136719\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5009/5009 [00:00<00:00, 1294471.27\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 2532276/2532276 [02:33<00:00, 1651\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 6396046/6396046 [06:55<00:00, 1537\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 205/205 [00:00<00:00, 367135.92it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1074/1074 [00:00<00:00, 1066197.04\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 36798/36798 [00:00<00:00, 979656.8\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 98/98 [00:00<00:00, 653484.57it/s]\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 37354/37354 [00:01<00:00, 34420.18\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 6057760/6057760 [09:03<00:00, 1114\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1482/1482 [00:00<00:00, 966111.06i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 110436/110436 [00:00<00:00, 118889\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 199/199 [00:00<00:00, 920249.72it/\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 547981/547981 [00:00<00:00, 137641\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 10924078/10924078 [17:04<00:00, 10\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 551/551 [00:00<00:00, 880404.38it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9750/9750 [00:00<00:00, 868266.08i\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 12810339/12810339 [23:54<00:00, 89\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 16665/16665 [00:00<00:00, 516489.5\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1152/1152 [00:00<00:00, 46214.25it\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 4267637/4267637 [05:26<00:00, 1305\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 5651425/5651425 [00:04<00:00, 1401\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 123255/123255 [00:00<00:00, 116307\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 547669/547669 [00:00<00:00, 137998\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "deconstruct into fuzzer target calls: 100%|█| 74405/74405 [00:00<00:00, 1197965.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 16670/16670 [00:00<00:00, 1206853.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 35200/35200 [00:00<00:00, 957454.6\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 2625508/2625508 [02:51<00:00, 1530\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 205/205 [00:00<00:00, 396601.62it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 22398561/22398561 [36:36<00:00, 10\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 14/14 [00:00<00:00, 203889.78it/s]\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 363459/363459 [00:00<00:00, 128329\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 11218417/11218417 [07:32<00:00, 24\u001b[A\n",
      "\n",
      "round 2:  71%|███████████████████        | 106/150 [4:58:42<5:03:31, 413.89s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "successes_2 = []\n",
    "failed_2 = []\n",
    "for fpath in tqdm.tqdm(failed_1, position=1, desc=\"round 2\"):\n",
    "    repair_path = recover_functions(fpath)\n",
    "    try:\n",
    "        root = ET.parse(repair_path).getroot()\n",
    "        successes_2.append(repair_path)\n",
    "        shutil.copyfile(repair_path, dstdir/repair_path.name)\n",
    "    except ET.ParseError as ex:\n",
    "        print(\"exception\", type(ex), ex, \"parsing\", fpath)\n",
    "        failed_2.append(repair_path)\n",
    "\n",
    "print(\"ROUND 2:\", len(failed_2), \"files failed parsing\")\n",
    "(dstdir/\"1_repair_success_2.txt\").write_text(\"\\n\".join(map(str, successes_2)))\n",
    "\n",
    "# root = ET.parse('traces-1m/trace-angus-mail-BASE64EncoderStreamFuzzer.xml').getroot()\n",
    "# root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_files = successes_1 + successes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(dstdir/\"1_repair_success_all.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(map(str, all_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ede1a196b76944c8f4443c0dcb7a1f7267d958f23434ac7797fa7d09f7c5ffd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
