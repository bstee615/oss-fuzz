{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. PARSE XML FILES\n",
    "2. TURN INTO TREE\n",
    "3. IF FAILS, PARSE AS MANY OF THE ENTRIES AS POSSIBLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285 XML files found, 285 unique. duplicates = []\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "import re\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "import git\n",
    "\n",
    "repo = git.Repo('.', search_parent_directories=True)\n",
    "os.chdir(repo.working_tree_dir)\n",
    "\n",
    "# srcpaths=(\n",
    "#     \"traces-1m-worker_3_overnight_portclash\",\n",
    "#     \"traces-1m-worker_4_overnight_fixportclash\",\n",
    "# )\n",
    "srcpaths=(\n",
    "    \"trace_run_3_success_3h/traces-10m/logs-xmls\",\n",
    ")\n",
    "\n",
    "xmls = []\n",
    "for d in srcpaths:\n",
    "    l = list(Path(d).glob(\"*.xml\"))\n",
    "    xmls += l\n",
    "print(len(xmls), \"XML files found,\", len(set([f.name for f in xmls])), \"unique. duplicates =\", [f for f in xmls if [g.name for g in xmls].count(f.name) > 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstdir=Path(\"postprocessed\")\n",
    "\n",
    "# if dstdir.exists():\n",
    "#     shutil.rmtree(dstdir)\n",
    "# dstdir.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes = (dstdir/\"1_repair_success_1.txt\").read_text().splitlines(keepends=False)\n",
    "len(successes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_1 = [p for p in xmls if str(p) not in successes]\n",
    "assert len(failed_1) == 150\n",
    "failed_1 = failed_1[105:]\n",
    "len(failed_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tqdm jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 285/285 [56:50<00:00, 11.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND 1: 150 files failed parsing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12980"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tqdm as tqdm\n",
    "\n",
    "successes_1 = []\n",
    "failed_1 = []\n",
    "for fpath in tqdm.tqdm(xmls):\n",
    "    try:\n",
    "        root = ET.parse(fpath).getroot()\n",
    "        # print(fpath, \"parsed successfully\")\n",
    "        successes_1.append(fpath)\n",
    "        shutil.copyfile(fpath, dstdir/fpath.name)\n",
    "    except ET.ParseError as ex:\n",
    "        # print(\"exception\", type(ex).__name__, ex, \"parsing\", fpath)\n",
    "        failed_1.append(fpath)\n",
    "\n",
    "print(\"ROUND 1:\", len(failed_1), \"files failed parsing\")\n",
    "(dstdir/\"1_repair_success_1.txt\").write_text(\"\\n\".join(map(str, successes_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm as tqdm\n",
    "\n",
    "fuzzer_start = re.compile(r'''<call[^>]*method=\"[^.\"]+.fuzzerTestOneInput\\([^)]+\\)\"[^>]*''')\n",
    "fuzzer_almost_end = re.compile(r'''<tracepoint[^>]+>''')\n",
    "method_re = re.compile(r'''method=\"[^.\"]+.fuzzerTestOneInput\\([^)]+\\)\"''')\n",
    "exit_re = re.compile(r'''type=\"exit\"''')\n",
    "fuzzer_real_end = re.compile(r'''</call>''')\n",
    "\n",
    "\n",
    "from xml.dom import minidom\n",
    "from xml.parsers.expat import ExpatError\n",
    "\n",
    "def prettify(rough_string):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    # rough_string = ET.tostring(elem)\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    \n",
    "    # text = reparsed.toprettyxml(indent=\" \" * 2)\n",
    "    # return \"\".join(text.splitlines(keepends=True)[1:])\n",
    "    \n",
    "    # return reparsed.childNodes[0].toprettyxml(indent=\" \" * 2)\n",
    "    \n",
    "    return reparsed.toprettyxml(indent=\"  \")\n",
    "\n",
    "def recover_functions(fpath):\n",
    "    with open(fpath) as f:\n",
    "        xmlstring = f.read()\n",
    "    xmllines = xmlstring.splitlines(keepends=True)\n",
    "    it = iter(xmllines)\n",
    "    repair_path = Path(str(fpath) + \".repair.xml\")\n",
    "    failed_functions = 0\n",
    "    all_functions = 0\n",
    "    with open(repair_path, \"w\") as outf:\n",
    "        with tqdm.tqdm(it, total=len(xmllines), desc=\"deconstruct into fuzzer target calls\") as pbar:\n",
    "            it = iter(pbar)\n",
    "            fuzz_functions = []\n",
    "            current_fuzz_function = None\n",
    "            try:\n",
    "                outf.write(next(it))\n",
    "                while True:\n",
    "                    line = next(it)\n",
    "                    if fuzzer_start.search(line):\n",
    "                        # print(\"start at\", line)\n",
    "                        # start fuzzed function\n",
    "                        current_fuzz_function = []\n",
    "                    if current_fuzz_function is not None:\n",
    "                        current_fuzz_function.append(line)\n",
    "                    m = fuzzer_almost_end.search(line)\n",
    "                    if m:\n",
    "                        tag = m.group(0)\n",
    "                        if method_re.search(tag) and exit_re.search(tag):\n",
    "                            # print(\"end at\", line)\n",
    "                            while True:\n",
    "                                line = next(it)\n",
    "                                # print(\"search end\", line)\n",
    "                                current_fuzz_function.append(line)\n",
    "                                if fuzzer_real_end.search(line):\n",
    "                                    # cap off fuzzed function\n",
    "                                    # print(\"end\", line)\n",
    "                                    all_functions += 1\n",
    "                                    try:\n",
    "                                        func_xml = \"\".join(current_fuzz_function)\n",
    "                                        # ET.fromstring(func_xml)\n",
    "                                        # print(func_xml)\n",
    "                                        func_xml = \"\".join(prettify(func_xml).splitlines(keepends=True)[1:])\n",
    "                                        outf.write(func_xml + \"\\n\")\n",
    "                                    except (ExpatError, ET.ParseError):\n",
    "                                        failed_functions += 1\n",
    "                                    pbar.set_postfix({\"all\": all_functions, \"failed\": failed_functions})\n",
    "                                    break\n",
    "            except StopIteration:\n",
    "                pass\n",
    "        outf.write(\"</trace>\")\n",
    "    \n",
    "#     print(\"found\", len(fuzz_functions), \"functions\")\n",
    "\n",
    "#     success_functions = []\n",
    "#     failed_functions = 0\n",
    "#     pbar = tqdm.tqdm(fuzz_functions, desc=\"parse individual fuzzer targets\")\n",
    "#     for fuzzed_function in pbar:\n",
    "#         try:\n",
    "#             root = ET.ElementTree(ET.fromstring(fuzzed_function)).getroot()\n",
    "#             # ET.indent(root, space=\"\\t\", level=0)\n",
    "#             success_functions.append(ET.tostring(root, encoding='unicode', method='xml'))\n",
    "#         except ET.ParseError as ex:\n",
    "#             # print(\"function exception\", type(ex), ex, \"parsing\", fpath)\n",
    "#             # print(fuzzed_function)\n",
    "#             failed_functions += 1\n",
    "#         pbar.set_postfix({\"failed\": failed_functions})\n",
    "    # print(\"failed\", failed_functions, \"out of\", all_functions, \"functions\")\n",
    "\n",
    "#     success_text = \"\\n\".join((xmllines[0], \"\".join(success_functions), \"</trace>\"))\n",
    "#     success_text = prettify(success_text)\n",
    "#     repair_path.write_text(\"\".join(success_text))\n",
    "    return repair_path\n",
    "\n",
    "# repair_path = recover_functions(\"traces-1m-worker_3_overnight_portclash/trace-apache-commons-cli-ParserFuzzer.xml\")\n",
    "# root = ET.parse(repair_path).getroot()\n",
    "# repair_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 11218417/11218417 [08:09<00:00, 22\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 15270182/15270182 [20:31<00:00, 12\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 178137/178137 [00:02<00:00, 70776.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 445291/445291 [00:00<00:00, 128340\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 635/635 [00:00<00:00, 1190072.85it\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 93354/93354 [00:03<00:00, 26917.21\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 667/667 [00:00<00:00, 900708.55it/\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 8584/8584 [00:00<00:00, 1050442.17\n",
      "deconstruct into fuzzer target calls: 100%|█| 2862536/2862536 [00:02<00:00, 1411\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35207/35207 [00:00<00:00, 959168.9\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35172/35172 [00:00<00:00, 657371.5\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1988647/1988647 [01:25<00:00, 2321\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 467463/467463 [00:30<00:00, 15531.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 262/262 [00:00<00:00, 968200.57it/\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 11111052/11111052 [15:59<00:00, 11\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 42805/42805 [00:16<00:00, 2612.41i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1172007/1172007 [00:06<00:00, 1888\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 7187945/7187945 [09:50<00:00, 1218\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 202152/202152 [00:00<00:00, 129083\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9660/9660 [00:00<00:00, 1170334.39\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 8030/8030 [00:00<00:00, 838798.13i\n",
      "deconstruct into fuzzer target calls: 100%|█| 151610/151610 [00:00<00:00, 129133\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 355335/355335 [00:00<00:00, 133708\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35183/35183 [00:00<00:00, 1142301.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 7781767/7781767 [04:28<00:00, 2901\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 7472192/7472192 [06:22<00:00, 1953\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1513047/1513047 [01:45<00:00, 1433\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35170/35170 [00:00<00:00, 1093058.\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 217236/217236 [00:00<00:00, 138247\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 35168/35168 [00:00<00:00, 1171402.\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 113/113 [00:00<00:00, 708454.94it/\n",
      "deconstruct into fuzzer target calls: 100%|█| 35190/35190 [00:00<00:00, 1198255.\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1496/1496 [00:00<00:00, 1006041.17\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 38180/38180 [00:00<00:00, 47106.44\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 13978714/13978714 [00:12<00:00, 11\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 772/772 [00:00<00:00, 661627.03it/\u001b[A\n",
      "deconstruct into fuzzer target calls: 100%|█| 39830/39830 [00:01<00:00, 25986.31\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 448430/448430 [00:00<00:00, 111205\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9420483/9420483 [16:06<00:00, 9746\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 4502/4502 [00:00<00:00, 793159.85i\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 4329144/4329144 [04:59<00:00, 1443\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 15473313/15473313 [19:24<00:00, 13\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 141719/141719 [00:00<00:00, 131693\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 1167101/1167101 [00:00<00:00, 1335\u001b[A\n",
      "\n",
      "deconstruct into fuzzer target calls: 100%|█| 9750/9750 [00:00<00:00, 1148398.32\u001b[A\n",
      "round 2: 100%|███████████████████████████████| 45/45 [2:05:06<00:00, 166.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUND 2: 0 files failed parsing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4399"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "successes_2 = []\n",
    "failed_2 = []\n",
    "for fpath in tqdm.tqdm(failed_1, position=1, desc=\"round 2\"):\n",
    "    repair_path = recover_functions(fpath)\n",
    "    try:\n",
    "        root = ET.parse(repair_path).getroot()\n",
    "        successes_2.append(repair_path)\n",
    "        shutil.copyfile(repair_path, dstdir/repair_path.name)\n",
    "    except ET.ParseError as ex:\n",
    "        print(\"exception\", type(ex), ex, \"parsing\", fpath)\n",
    "        failed_2.append(repair_path)\n",
    "\n",
    "print(\"ROUND 2:\", len(failed_2), \"files failed parsing\")\n",
    "(dstdir/\"1_repair_success_2_part2.txt\").write_text(\"\\n\".join(map(str, successes_2)))\n",
    "\n",
    "# root = ET.parse('traces-1m/trace-angus-mail-BASE64EncoderStreamFuzzer.xml').getroot()\n",
    "# root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_files = successes_1 + successes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(dstdir/\"1_repair_success_all.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(map(str, all_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5ede1a196b76944c8f4443c0dcb7a1f7267d958f23434ac7797fa7d09f7c5ffd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
